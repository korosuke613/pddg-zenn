---
title: "仮想サーバ基盤を構築する"
---

## 物理マシンでサービスを提供する

物理マシンにOSをインストールし、Webサーバを入れ、サービスを提供することももちろん可能です。余計なオーバーヘッドもなく、パフォーマンスも良いかも知れません。
一方で、この構成はメンテナンスが難しくなることもあります。

- 一つのOS内に様々なものがインストールされているとアップデート時や再起動時に考慮が必要なものが多くなる
  - あるライブラリやランタイムの更新時にそれによって影響を受ける範囲をしっかり考慮しなければならない
  - 同じPythonを使うソフトウェアでも、それらが要求するバージョンなどは異なるかもしれない
- 物理マシンは再起動にかかるコストが重い
  - ハードウェア周りの処理が入るためサーバの起動には時間がかかる
  - 再起動を要するメンテナンスにかかる時間が長くなるためあまり頻繁に実施したくない

とはいえ物理マシンは大抵高いスペックを持つため一台あたりが高価であり、依存関係のためだけにわざわざ複数台の物理マシンを用意するのは現実的とは言えません。この高スペックを活かし、かつコンポーネント間を疎結合にして管理しやすくする方法は無いものでしょうか？
そのために必要な概念としてコンピューティングリソースの抽象化について考えて見ます。

### コンピューティングリソースの割り振りとコンポーネントの分離

まずコンピューティングリソースとはCPUやメモリ・ディスクの容量など、物理マシンがサービス提供に供与可能なリソース量を指します。ここに4コア、32GBメモリ、256GBのディスク容量があるサーバが3台あるとき、利用可能なコンピューティングリソースとしては12コア、96GBメモリ、768GBのディスクがある事になります。ただしこの96GBのメモリが単一のプロセスで利用可能なわけでは無いことには注意が必要です。

物理マシンが単なるコンピューティングリソースを供与するものであると考えると、反対にサービスを提供するプロセスはコンピューティングリソースを消費するものに当たります。プロセスがどれくらいリソースを消費するかを考慮した上でそれが実現できる物理マシンに適切に配置することが重要です。ここでは複数あるサーバ一つ一つは単なるコンピューティングリソースの塊であって、どのプロセスがどこに配置されるかは単にコンピューティングリソースの都合によって決まります。

ただし単にプロセスを配置すると言っても、やり方を考えなければ前述したように一つの物理マシンの中で複雑に絡まり合い、メンテナンスを困難にしてしまいます。そこで、仮想的な「箱」を用意し、その「箱」に対してリソースを割り当てることを考えます。この「箱」は他の「箱」や「箱」を収容するホストに直接干渉することはできず、それらが利用可能なリソース以上にリソースを利用できないようになっているとします。

この状態では、各「箱」ごとにメンテナンスが可能になります。またコンピューティングリソースの割り振りを変えることで、各「箱」の使えるリソース量を変更することもできます。
この一つ一つの「箱」を **仮想マシン（VM）** と呼びます。Linuxには仮想マシンを作るための機能があり、適切に利用することでホストのコンピューティングリソースを仮想マシンごとにそれぞれ割り振ることができるようになっています[^why-no-container]。

[^why-no-container]: 現代にはコンテナと呼ばれる仮想化技術も存在します。これらはLinuxのcgroup（リソースの割り振り・制限ができる）やnamespace（プロセスごとに見える空間の分離）などを使って、この「箱」のようなものを作ることが出来るようになっています。ただし、Linuxカーネル自体はホストのものを共有するような作りになっているものが多く使われており、完全に分離されているわけではありません。VMの場合はホストとは異なるバージョンのカーネルを使うこともできます。今回の範囲ではコンテナは一旦取り扱いませんが、同様の構成をコンテナで行う場合何に気をつけなければならないか、逆に何かメリットはあるかなど考えてみるのも面白いでしょう。

## 仮想マシン（VM）とは

VM（Virtual Machineの略）とは「実際のコンピューターのように動作するコンピューター ファイル」[^ms-vm-dev]です。これらは普通にサーバを使っている時のようにCPU・メモリ・ディスクなどを持ち、ネットワークで通信することが出来ますが、その実体は物理マシンのリソースを抽象化したものを操っており物理的に目に見えるものではありません。

[^ms-vm-def]: https://azure.microsoft.com/ja-jp/resources/cloud-computing-dictionary/what-is-a-virtual-machine

VMはCPUやメモリ・ディスク・NICのようなハードウェアをエミュレートし、同様のふるまいをするソフトウェアやハードウェアの支援機能を活用しています。有償の物からOSSまで様々な仮想化ソフトウェアが存在しており、ライブラリも整備されているのでユーザはそれらを活用することでボタンを押したら仮想マシンが立ち上がる、みたいな機能を実装することも出来ます。AWS EC2やGoogle Compute Engineなどでインスタンスを立ち上げるのと似たような機能を個人で実装することもできます。

物理マシンと同じように振る舞うので、通常の物理マシンと同じようにしてOSをインストールして使うことが出来ます。仮想的なディスクドライブとしてISOファイルをマウントし、与えられた仮想的なディスクのパーティションを分割してOSをインストールし、そのディスクから起動して……といった感じです。当然グラフィックデバイスも仮想化でき、VMの画面をリモートから見ることができるような技術も存在します。

### なぜVMを用いるのか

ケースに応じて多様な事情が存在します。使わないのが悪いと言うことでは無くケースバイケースであり、以下の様な例に該当する場合は採用してみると良いでしょう。今回の演習では、こういうやり方をすることもできますよという一例を示すため、またユーザごとの環境をできる限り均質化するためにVMを利用します。

- アプリケーションやミドルウェアの実行環境を分離するため
  - それぞれを個別に更新でき、互いの変更がOSやライブラリのレベルでは影響しない
- 管理するチームが異なっておりそれぞれに適切な権限を付与したい
  - 複数のアプリケーションをそれぞれ異なるチームが運用する際、全員が全てのアプリケーションへの管理者権限を持つというのは過剰である
  - 異なるVMに分けてそれぞれへの権限を適切なチームが持つことで、事故を防止しセキュリティを向上できる
- 物理マシンは柔軟な管理が難しく管理のコストが大きいため
  - VMの起動コストよりも物理マシンの起動コストの方が遥かに大きい
  - 物理マシンを状態そっくりそのまま入れ替えることは難しいが、VMならば状態を保存したまま物理マシン間を移動することも可能[^vm-miration]

[^vm-migration]: これはマイグレーションと呼ばれる操作ですが、今回は取り扱いません。VMをシャットダウンしてから移動させる方法や、VMを起動したまま移動させるライブマイグレーションと呼ばれるものまであります。メンテナンスしたいサーバからVMを適切に移動させることで、サービス断や再セットアップの手間を抑えて効率的にメンテナンスできます。

### 様々な仮想化製品

これらが厳密にどのような機能を提供する仮想化ソフトウェアなのかは詳しく解説しません。おそらく名前だけは聞いたことあるみたいなこれらのソフトウェアは、VMを作成するといった仮想化の機能を提供しているソフトウェアであると覚えてもらえれば良いかなと考えています。

- [Windows Hyper-V](https://learn.microsoft.com/ja-jp/virtualization/hyper-v-on-windows/about/)
- [Linux KVM](https://linux-kvm.org/page/Main_Page)
- [VirtualBox](https://www.virtualbox.org/)
- [VMware ESXi](https://www.vmware.com/jp/products/esxi-and-esx.html)
- [Nutanix AHV](https://www.nutanix.com/jp/products/ahv)

今回は主にKVM（とQEMU）を用いたVMを提供する、[Proxmox VE](https://pve.proxmox.com/pve-docs/)というOSSを用いてVM基盤を構築していきます。まずは中身については触れず、実際にVMを作って遊べるようにします。

## Proxmox VEのインストール

:::message
Proxmox VEのバージョン8.1.3を用いて動作を検証しています。他のバージョンではUIや機能などが異なる可能性があります。
異なるバージョンで挑戦する場合、また詳細なインストール方法については下記のページを参照してください。
https://pve.proxmox.com/pve-docs/chapter-pve-installation.html
:::

### インストール用USBメモリを作成する

Proxmox VEのISOをダウンロードし、起動可能な形式でUSBメモリに書き込みます。このUSBメモリをサーバとして利用するマシンに挿して起動することでインストールを開始できます。
以下のページから最新のProxmox VEのISOファイルをダウンロードしてください。
https://www.proxmox.com/en/downloads/proxmox-virtual-environment/iso

ダウンロードしたISOファイルを各プラットフォームごとに異なる方法を使ってUSBメモリに書き込みます。

:::message alert
ここで用いるUSBメモリに保存されているデータは全て削除されます。重要なデータを失わないよう、中身を確認した上で利用してください。
誤って重要なデータが削除されてしまった場合でも、筆者は一切の責任を負いかねます。
:::

:::details Windowsの場合
[Rufas](https://github.com/pbatard/rufus)を使います。[最新のリリース](https://github.com/pbatard/rufus/releases)からexeファイルをダウンロードして実行してください。

![rufas-window.png](/images/books/introduction-for-high-availability/rufas-window.png)

各項目をそれぞれ設定し、スタートを押してください。

- デバイス：あなたが書き込みたいUSBメモリ
- ブートの種類：「選択」からダウンロードしたISOファイルを指定する

ISOファイルを指定する際に下記の様な警告が表示されることがありますが、OKを押して進んでください。

![rufas-warn-window.png](/images/books/introduction-for-high-availability/rufas-warn-window.png)

スタートをクリックした後、準備完了になれば正しく書き込めています。

![rufas-complete-window.png](/images/books/introduction-for-high-availability/rufas-complete-window.png)
:::

:::details macOSの場合
以下のページを参照してください。
https://pve.proxmox.com/pve-docs/chapter-pve-installation.html#_instructions_for_macos
:::

:::details Linuxの場合
以下のページを参照してください。
https://pve.proxmox.com/pve-docs/chapter-pve-installation.html#_instructions_for_gnu_linux
:::
